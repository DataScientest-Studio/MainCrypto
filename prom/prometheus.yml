# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alert-manager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "alertmanager/monitoring_rules.yml" # pour correspondre à l'arborescence actuelle

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  #   # metrics_path defaults to '/metrics'
  #   # scheme defaults to 'http'
  - job_name: "node"
    scrape_interval: 5s
    static_configs:
    - targets: 
      - node-exporter:9100  # scraping node exporter 

  - job_name: "airflow_statsd"
    scrape_interval: 5s
    static_configs:
    - targets:
      - statsd-exporter:9102 # with stats-exporter, or prometheus:9090 within statsd

  - job_name: "prediction_api"
    scrape_interval: 5s
    static_configs:
    - targets:
      - prediction-api:3001 

# pas utilisé manifestement
    
#  - job_name: "airflow-webserver"
#    scrape_interval: 5s
#    static_configs:
#    - targets:
#      - airflow-webserver:8080 # a voir     
